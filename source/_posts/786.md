---
title: 通过 Nginx 的 access_log 分析网站的流量
tags:
  - 网站
categories:
  - 运维教程
date: 2026-01-07 00:00:00
---

> 在当今数字化时代，网站流量分析对于理解用户行为、优化网站性能以及制定营销策略至关重要。Nginx 作为一款高性能的 Web 服务器，其 access_log 日志文件记录了网站访问的详细信息，为我们提供了丰富的数据源。本文将深入探讨如何通过分析 Nginx 的 access_log 来获取网站流量的多维度数据，并给出具体的操作步骤和分析方法。

<!-- more -->

## Nginx access_log 日志格式
在开始分析之前，我们需要了解 Nginx access_log 的默认日志格式。通常情况下，access_log 的日志格式如下：
```
log_format combined '$remote_addr - $remote_user [$time_local] '
                    '"$request" $status $body_bytes_sent '
                    '"$http_referer" "$http_user_agent"';
```
这个格式包含了以下字段：
- `$remote_addr`：客户端 IP 地址
- `$remote_user`：客户端用户名称（基本认证的用户名，通常为 `-`）
- `$time_local`：本地时间
- `$request`：请求方法、请求 URI 和 HTTP 版本
- `$status`：HTTP 状态码
- `$body_bytes_sent`：发送给客户端的字节数（不包括响应头）
- `$http_referer`：请求来源 URL
- `$http_user_agent`：客户端浏览器的用户代理字符串

## 访问量分析
### 总访问量统计
要统计网站的总访问量，可以通过计算 access_log 文件的行数来实现。在 Linux 系统中，可以使用 `wc -l` 命令：
```bash
wc -l access.log
```
该命令会输出 access.log 文件的行数，即为网站的总访问量。

### 访问量时间分布
了解访问量在不同时间段的分布情况，有助于我们发现网站的访问高峰和低谷。可以使用 `awk` 命令按小时或分钟统计请求数：
```bash
# 按每小时统计请求数
awk '{print $4}' access.log | cut -c 14-15 | sort | uniq -c | sort -nr | head -n 100

# 按每分钟统计请求数
awk '{print $4}' access.log | cut -c 14-18 | sort | uniq -c | sort -nr | head -n 100
```
这些命令会输出按小时或分钟统计的请求数，并显示请求数最多的前 100 个时间点。

## 访问来源分析
### 来源 IP 分析
分析访问来源 IP，可以了解用户主要来自哪些地区或网络环境。使用 `awk` 和 `sort` 命令可以统计访问量最多的 IP 地址：
```bash
awk '{print $1}' access.log | sort | uniq -c | sort -nr | head -n 10
```
该命令会输出访问量最多的前 10 个 IP 地址及其访问次数。

### 来源 URL 分析
查看访问来源 URL，有助于我们了解用户是如何找到我们网站的。可以使用以下命令统计访问来源最多的 URL：
```bash
awk '{print $11}' access.log | sort | uniq -c | sort -nr | head -n 10
```
该命令会输出访问来源最多的前 10 个 URL 及其访问次数。

## 页面访问分析
### 访问最频繁的页面
了解哪些页面访问量最高，可以帮助我们优化这些页面的性能和内容。使用 `awk` 命令可以统计访问最频繁的页面：
```bash
awk '{print $7}' access.log | sort | uniq -c | sort -rn | head -n 100
```
该命令会输出访问最频繁的前 100 个页面及其访问次数。

### 页面访问时间分析
分析页面的访问时间，可以发现哪些页面的加载时间较长，需要优化。在 Nginx 的 log_format 中加入 `$request_time` 字段，然后使用以下命令列出传输时间超过 3 秒的页面：
```bash
cat access.log | awk '($NF > 3){print $7}' | sort -n | uniq -c | sort -nr | head -20
```
该命令会输出传输时间超过 3 秒的页面及其出现的次数，显示前 20 条记录。

## 用户行为分析
### 用户代理分析
分析用户代理字符串，可以了解用户使用的浏览器类型和版本。使用 `awk` 命令可以统计不同浏览器的访问次数：
```bash
awk -F '"' '{print $6}' access.log | sort | uniq -c | sort -nr | head -n 10
```
该命令会输出不同浏览器的访问次数及其用户代理字符串。

### 访问路径分析
通过分析用户的访问路径，可以了解用户在网站中的导航行为。可以使用以下命令统计访问路径的长度和频率：
```bash
awk '{print $7}' access.log | awk -F '/' '{print NF-1}' | sort | uniq -c | sort -nr | head -n 10
```
该命令会输出访问路径的长度及其出现的次数，显示前 10 条记录。

## 性能分析
### 响应时间分析
响应时间是衡量网站性能的重要指标之一。可以使用以下命令统计响应时间的分布情况：
```bash
awk '{print $NF}' access.log | sort -n | uniq -c | sort -nr | head -n 10
```
该命令会输出响应时间及其出现的次数，显示前 10 条记录。

### 状态码分析
HTTP 状态码反映了请求的成功与否以及错误类型。可以使用以下命令统计不同状态码的出现次数：
```bash
awk '{print $9}' access.log | sort | uniq -c | sort -nr | head -n 10
```
该命令会输出不同状态码及其出现的次数，显示前 10 条记录。

## 日志可视化与工具推荐
虽然通过命令行可以进行详细的日志分析，但可视化工具可以更直观地展示分析结果。以下是一些常用的日志分析工具：
- **GoAccess**：一款开源的实时日志分析器，支持多种日志格式，可以生成动态的 HTML 报告。
- **ELK Stack**：由 Elasticsearch、Logstash 和 Kibana 组成的日志处理和可视化平台，可以处理大规模的日志数据。
- **Matomo**：一款开源的网站分析工具，支持自托管，可以对网站流量进行详细的分析和可视化展示。

## 结论
通过深入分析 Nginx 的 access_log，我们可以从多个维度了解网站的流量情况，包括访问量、访问来源、页面访问、用户行为和性能等。这些分析结果对于网站的优化、用户体验提升和业务决策都具有重要的指导意义。同时，结合可视化工具，可以更高效地展示和理解分析数据，为网站的发展提供有力的支持。